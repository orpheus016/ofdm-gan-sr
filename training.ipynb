{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3b42893",
   "metadata": {},
   "source": [
    "# OFDM-GAN-SR Training on Google Colab\n",
    "\n",
    "This notebook trains the CWGAN-GP model for OFDM signal reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c32b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/orpheus016/ofdm-gan-sr.git\n",
    "%cd ofdm-gan-sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74a6960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c5a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model architectures before training\n",
    "import torch\n",
    "from models.generator import UNetGenerator\n",
    "from models.discriminator import Discriminator\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL VALIDATION TEST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\n✓ Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# Initialize models\n",
    "print(\"\\n[1/5] Initializing Generator...\")\n",
    "generator = UNetGenerator(\n",
    "    input_channels=2,\n",
    "    output_channels=2,\n",
    "    base_channels=32,\n",
    "    depth=5\n",
    ").to(device)\n",
    "\n",
    "print(\"[2/5] Initializing Discriminator...\")\n",
    "discriminator = Discriminator(\n",
    "    input_channels=4,  # 2 (candidate) + 2 (condition)\n",
    "    base_channels=32,\n",
    "    num_layers=6\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "gen_params = sum(p.numel() for p in generator.parameters())\n",
    "disc_params = sum(p.numel() for p in discriminator.parameters())\n",
    "print(f\"\\n✓ Generator parameters: {gen_params:,}\")\n",
    "print(f\"✓ Discriminator parameters: {disc_params:,}\")\n",
    "\n",
    "# Test forward pass\n",
    "print(\"\\n[3/5] Testing Generator forward pass...\")\n",
    "batch_size = 4\n",
    "noisy_signal = torch.randn(batch_size, 2, 1024).to(device)\n",
    "\n",
    "try:\n",
    "    fake_signal = generator(noisy_signal)\n",
    "    assert fake_signal.shape == (batch_size, 2, 1024), \\\n",
    "        f\"Generator output shape mismatch: {fake_signal.shape}\"\n",
    "    print(f\"✓ Generator output shape: {tuple(fake_signal.shape)}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Generator test FAILED: {e}\")\n",
    "    raise\n",
    "\n",
    "# Test discriminator\n",
    "print(\"\\n[4/5] Testing Discriminator forward pass...\")\n",
    "clean_signal = torch.randn(batch_size, 2, 1024).to(device)\n",
    "condition = noisy_signal  # Use noisy as condition\n",
    "\n",
    "try:\n",
    "    # Concatenate along channel dimension\n",
    "    disc_input = torch.cat([fake_signal.detach(), condition], dim=1)\n",
    "    score = discriminator(disc_input)\n",
    "    print(f\"✓ Discriminator output shape: {tuple(score.shape)}\")\n",
    "    print(f\"✓ Score range: [{score.min().item():.3f}, {score.max().item():.3f}]\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Discriminator test FAILED: {e}\")\n",
    "    raise\n",
    "\n",
    "# Memory usage\n",
    "print(\"\\n[5/5] Checking memory usage...\")\n",
    "if torch.cuda.is_available():\n",
    "    allocated = torch.cuda.memory_allocated(device) / 1e9\n",
    "    reserved = torch.cuda.memory_reserved(device) / 1e9\n",
    "    print(f\"✓ GPU Memory: {allocated:.2f} GB allocated, {reserved:.2f} GB reserved\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"✅ ALL TESTS PASSED - Models are ready for training!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c985fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training with fixed configuration\n",
    "!python train.py --synthetic --epochs 100 --lr 0.0001 --batch_size 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a49659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Monitor training with TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04816b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Save checkpoints to Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create backup directory\n",
    "!mkdir -p /content/drive/MyDrive/ofdm-gan-checkpoints\n",
    "\n",
    "# Copy checkpoints (run this after training completes or periodically)\n",
    "!cp -r checkpoints/* /content/drive/MyDrive/ofdm-gan-checkpoints/\n",
    "!cp -r runs/* /content/drive/MyDrive/ofdm-gan-checkpoints/runs/\n",
    "\n",
    "print(\"✓ Checkpoints saved to Google Drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc6d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --synthetic --epochs 100 --lr 0.0001"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
