{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3b42893",
   "metadata": {},
   "source": [
    "# OFDM-GAN-SR Training on Google Colab\n",
    "\n",
    "This notebook trains the CWGAN-GP model for OFDM signal reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c32b62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ofdm-gan-sr'...\n",
      "remote: Enumerating objects: 90, done.\u001b[K\n",
      "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
      "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
      "remote: Total 90 (delta 38), reused 78 (delta 30), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (90/90), 590.91 KiB | 11.36 MiB/s, done.\n",
      "Resolving deltas: 100% (38/38), done.\n",
      "/content/ofdm-gan-sr\n"
     ]
    }
   ],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/orpheus016/ofdm-gan-sr.git\n",
    "%cd ofdm-gan-sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e74a6960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.6/626.6 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.0/118.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.2/106.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/14.5 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.8/59.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires ipykernel==6.17.1, but you have ipykernel 7.1.0 which is incompatible.\n",
      "jupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.7.0 which is incompatible.\n",
      "jupyter-kernel-gateway 2.5.2 requires notebook<7.0,>=5.7.6, but you have notebook 7.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c5a23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MODEL VALIDATION TEST\n",
      "============================================================\n",
      "\n",
      "✓ Device: cpu\n",
      "\n",
      "[1/5] Initializing Generator...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "UNetGenerator.__init__() got an unexpected keyword argument 'in_channels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-225442429.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Initialize models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n[1/5] Initializing Generator...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m generator = UNetGenerator(\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: UNetGenerator.__init__() got an unexpected keyword argument 'in_channels'"
     ]
    }
   ],
   "source": [
    "# Test model architectures before training\n",
    "import torch\n",
    "from models.generator import UNetGenerator\n",
    "from models.discriminator import Discriminator\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL VALIDATION TEST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\n✓ Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# Initialize models\n",
    "print(\"\\n[1/5] Initializing Generator...\")\n",
    "generator = UNetGenerator(\n",
    "    input_channels=2,\n",
    "    output_channels=2,\n",
    "    base_channels=32,\n",
    "    depth=5\n",
    ").to(device)\n",
    "\n",
    "print(\"[2/5] Initializing Discriminator...\")\n",
    "discriminator = Discriminator(\n",
    "    input_channels=4,  # 2 (candidate) + 2 (condition)\n",
    "    base_channels=32,\n",
    "    num_layers=6\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "gen_params = sum(p.numel() for p in generator.parameters())\n",
    "disc_params = sum(p.numel() for p in discriminator.parameters())\n",
    "print(f\"\\n✓ Generator parameters: {gen_params:,}\")\n",
    "print(f\"✓ Discriminator parameters: {disc_params:,}\")\n",
    "\n",
    "# Test forward pass\n",
    "print(\"\\n[3/5] Testing Generator forward pass...\")\n",
    "batch_size = 4\n",
    "noisy_signal = torch.randn(batch_size, 2, 1024).to(device)\n",
    "\n",
    "try:\n",
    "    fake_signal = generator(noisy_signal)\n",
    "    assert fake_signal.shape == (batch_size, 2, 1024), \\\n",
    "        f\"Generator output shape mismatch: {fake_signal.shape}\"\n",
    "    print(f\"✓ Generator output shape: {tuple(fake_signal.shape)}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Generator test FAILED: {e}\")\n",
    "    raise\n",
    "\n",
    "# Test discriminator\n",
    "print(\"\\n[4/5] Testing Discriminator forward pass...\")\n",
    "clean_signal = torch.randn(batch_size, 2, 1024).to(device)\n",
    "condition = noisy_signal  # Use noisy as condition\n",
    "\n",
    "try:\n",
    "    # Concatenate along channel dimension\n",
    "    disc_input = torch.cat([fake_signal.detach(), condition], dim=1)\n",
    "    score = discriminator(disc_input)\n",
    "    print(f\"✓ Discriminator output shape: {tuple(score.shape)}\")\n",
    "    print(f\"✓ Score range: [{score.min().item():.3f}, {score.max().item():.3f}]\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Discriminator test FAILED: {e}\")\n",
    "    raise\n",
    "\n",
    "# Memory usage\n",
    "print(\"\\n[5/5] Checking memory usage...\")\n",
    "if torch.cuda.is_available():\n",
    "    allocated = torch.cuda.memory_allocated(device) / 1e9\n",
    "    reserved = torch.cuda.memory_reserved(device) / 1e9\n",
    "    print(f\"✓ GPU Memory: {allocated:.2f} GB allocated, {reserved:.2f} GB reserved\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"✅ ALL TESTS PASSED - Models are ready for training!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c985fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training with fixed configuration\n",
    "!python train.py --synthetic --epochs 100 --lr 0.0001 --batch_size 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a49659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Monitor training with TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04816b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Save checkpoints to Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create backup directory\n",
    "!mkdir -p /content/drive/MyDrive/ofdm-gan-checkpoints\n",
    "\n",
    "# Copy checkpoints (run this after training completes or periodically)\n",
    "!cp -r checkpoints/* /content/drive/MyDrive/ofdm-gan-checkpoints/\n",
    "!cp -r runs/* /content/drive/MyDrive/ofdm-gan-checkpoints/runs/\n",
    "\n",
    "print(\"✓ Checkpoints saved to Google Drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bc6d199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-17 08:12:33.209592: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-17 08:12:33.217639: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-17 08:12:33.241777: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765959153.292940   13039 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765959153.306888   13039 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1765959153.344960   13039 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765959153.345054   13039 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765959153.345060   13039 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1765959153.345065   13039 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-12-17 08:12:33.355808: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Using synthetic OFDM dataset\n",
      "Generator parameters: 5,504,258\n",
      "Discriminator parameters: 1,311,073\n",
      "Training for 100 epochs\n",
      "Device: cpu\n",
      "Batch size: 32\n",
      "N critic: 5\n",
      "GP weight: 10.0\n",
      "Reconstruction weight: 100.0\n",
      "Epoch 0:   0% 0/312 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Epoch 0:   0% 0/312 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/ofdm-gan-sr/train.py\", line 637, in <module>\n",
      "    main()\n",
      "  File \"/content/ofdm-gan-sr/train.py\", line 633, in main\n",
      "    trainer.train(experiment_name=args.experiment)\n",
      "  File \"/content/ofdm-gan-sr/train.py\", line 476, in train\n",
      "    train_losses = self.train_epoch(epoch)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/content/ofdm-gan-sr/train.py\", line 334, in train_epoch\n",
      "    d_losses = self.train_discriminator(clean, noisy)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/content/ofdm-gan-sr/train.py\", line 226, in train_discriminator\n",
      "    fake_signal = self.generator(noisy_signal)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/content/ofdm-gan-sr/models/generator.py\", line 472, in forward\n",
      "    d5 = d5 + e5  # Additive skip connection\n",
      "         ~~~^~~~\n",
      "RuntimeError: The size of tensor a (64) must match the size of tensor b (32) at non-singleton dimension 2\n"
     ]
    }
   ],
   "source": [
    "!python train.py --synthetic --epochs 100 --lr 0.0001"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
